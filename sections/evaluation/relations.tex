To evaluate which set of predicates performs best, again a database of cases is generated by running the agent in create-only mode.
For every case, enough information is saved such that Predicates can be generated after the agent finishes. For each set of Predicates, the corresponding Prolog rules can now be generated and the agent can be run in CBR-only mode. This means that the agent tries to find a matching CBR case from the database and executes the best available. If no case matches better then a threshold, the agent targets a pig directly. In this mode, no new cases are generated and cases are not updated, to limit randomness. Due to stochastic elements in the scene matching, which have been discussed earlier, randomness cannot be entirely avoided.

Because the agent runs on the same database for every set of predicates, the results are comparable. For each set of predicates, the appropriate case database was generated and the agent was run for 60 minutes. The Level selection module was set to first iteratively play every level before any levels can be attempted again.
This also improves comparability between runs. Applicability of cases was determined with 50 iterations of the wmch algorithm.

During the runs, every action the agent performs is logged, so that the run can be analyzed afterwards. Relevant data includes the strategies that were considered and which strategy was chosen for each shot, the results of a shot, expected and actual effects for CBR shots and the score if a level is beaten.

This information allows the run to be reconstructed and analyzed at any time.

For this purpose, performance of a case is judged by whether it killed the pigs it promised to, regardless of other objects that should have been affected.
% TODO: add results: