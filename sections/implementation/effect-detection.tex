Objects are classified as either affected or unaffected by a shot.
If an object was neither destroyed nor moved by a shot, it is considered unaffected.
All other objects are therefore affected and are further classified as being either destroyed or moved.

Determining which object were unaffected is simple, because by definition they both still exists and are at the same position as before the execution of the shot. The harder part is dividing all other objects into either moved or destroyed objects.
This is, at least in part, due to the limited information the agent has: one screenshot before and one after the shot was executed and objects have stopped moving and no consistent ids that would allow matching objects between the two.

After making use of the computer vision module, we have two sets of objects, $before$ and $after$. Every object that appears in both sets with same shape, same material and similar coordinates can be eliminated from both sets, as by definition it has not been affected by the shot.
Due to uncertainty added by the computer vision module, coordinates do not have to be the exact same, but can deviate by 5 pixels and still be considered unchanged. In theory, objects could have been moved but ended up in the same place, but this cannot be detected without additional information.

The two sets $before$ and $after$ now contain only objects that have been affected.
For every object $x$ of $before$ a list of potential matches is compiled. A potential match is an object $y$ of $after$, which has the same shape, material and a similar area (again, due to uncertainty). The coordinates are not considered at this point, however they must be different as otherwise the object would have been removed earlier.
If no matching object for $x$ is found, it must have been destroyed and can be removed from $before$. Otherwise, $x$ is added to a list of associated objects for every $y$.

The remaining objects of $before$ are not yet classified however. Even though every object has at least one potential match, there could be multiple objects in $before$ that match (only) the same object from $after$. In this case, only one of them could have moved, the others must have been destroyed. Thus, if an object $y$ from $after$ has multiple possible matches from $before$, it is assumed that the physically closest matching object in $before$ has moved and both objects can be removed from the sets. At this point, if there are remaining objects in $before$, they must have been destroyed.

This approach is not perfect, but works reasonably well. Apart from more screenshots, which could be used to track objects, future iterations could consider whether physical simulations or heuristics could be used to further improve this part. A possible heuristic could be that objects are likely to move to the right when hit from the left, although this might not be true when slopes come into play or when structures collapse.


